# ğŸ“° Fake News Classifier (BoW, TF-IDF, Word Embeddings)

This NLP project classifies news articles as **Real** or **Fake** using three powerful vectorization techniques:  
**Bag of Words**, **TF-IDF**, and **Word2Vec**. It demonstrates the evolution from basic count-based methods to semantic-aware embeddings.

---

## ğŸš€ Project Structure

FakeNewsClassifier/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Fake.csv
â”‚   â””â”€â”€ True.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_BoW_FakeNews.ipynb
â”‚   â”œâ”€â”€ 2_TFIDF_FakeNews.ipynb
â”‚   â””â”€â”€ 3_Embeddings_FakeNews.ipynb
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (optional: saved models)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocessing.py (optional)
â”œâ”€â”€ README.md

---

## ğŸ“‚ Dataset

- **Source**: [Fake and Real News Dataset on Kaggle](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)
- Combined and cleaned `Fake.csv` and `True.csv`
- Removed duplicates and retained only the `text` and `label` columns

---

## ğŸ§ª Model Comparison Results

| Vectorization | Accuracy | F1 Score (Real / Fake) | Notes |
|---------------|----------|------------------------|-------|
| **BoW**       | **99.47%** | 1.00 / 0.99 | Best overall performer |
| **TF-IDF**    | 98.70%   | 0.99 / 0.99 | Slightly lower, but robust |
| **Word2Vec**  | 97.89%   | 0.98 / 0.98 | Captures semantic relationships |

âœ”ï¸ All models used **Logistic Regression**  
âœ”ï¸ All preprocessing: lowercasing, punctuation removal, stop words  
âŒ No deep learning â€” yet powerful results!

---

## ğŸ“Š Embedding Visualization

Used **t-SNE** to visualize Word2Vec embeddings of top 300 frequent terms. Similar words cluster close together (e.g., politics, economy, war).

---

## ğŸ”§ Installation

pip install -r requirements.txt